{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 13:01:16.703669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 13:01:16.871932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-31 13:01:16.871953: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-31 13:01:16.902346: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-31 13:01:18.067851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-31 13:01:18.068194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-31 13:01:18.068215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "california_housing = fetch_california_housing(as_frame=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def build_sequential(lr, input_dims, output_dims, layerSizes, activation, loss):\n",
    "    model = keras.Sequential()\n",
    "    model.add (keras.layers.Input(shape=input_dims))\n",
    "    for size in layerSizes:\n",
    "        model.add(keras.layers.Dense(size))\n",
    "        model.add(keras.layers.LeakyReLU(alpha=0.05))\n",
    "\n",
    "    model.add(keras.layers.Dense(output_dims,activation=activation))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=loss)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n\n   Longitude  \n0    -122.23  \n1    -122.22  \n2    -122.24  \n3    -122.25  \n4    -122.25  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.3252</td>\n      <td>41.0</td>\n      <td>6.984127</td>\n      <td>1.023810</td>\n      <td>322.0</td>\n      <td>2.555556</td>\n      <td>37.88</td>\n      <td>-122.23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.3014</td>\n      <td>21.0</td>\n      <td>6.238137</td>\n      <td>0.971880</td>\n      <td>2401.0</td>\n      <td>2.109842</td>\n      <td>37.86</td>\n      <td>-122.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.2574</td>\n      <td>52.0</td>\n      <td>8.288136</td>\n      <td>1.073446</td>\n      <td>496.0</td>\n      <td>2.802260</td>\n      <td>37.85</td>\n      <td>-122.24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.6431</td>\n      <td>52.0</td>\n      <td>5.817352</td>\n      <td>1.073059</td>\n      <td>558.0</td>\n      <td>2.547945</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.8462</td>\n      <td>52.0</td>\n      <td>6.281853</td>\n      <td>1.081081</td>\n      <td>565.0</td>\n      <td>2.181467</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing.data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "0    4.526\n1    3.585\n2    3.521\n3    3.413\n4    3.422\nName: MedHouseVal, dtype: float64"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing.target.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.34476576,  0.98214266,  0.62855945, ..., -0.04959654,\n         1.05254828, -1.32783522],\n       [ 2.33223796, -0.60701891,  0.32704136, ..., -0.09251223,\n         1.04318455, -1.32284391],\n       [ 1.7826994 ,  1.85618152,  1.15562047, ..., -0.02584253,\n         1.03850269, -1.33282653],\n       ...,\n       [-1.14259331, -0.92485123, -0.09031802, ..., -0.0717345 ,\n         1.77823747, -0.8237132 ],\n       [-1.05458292, -0.84539315, -0.04021111, ..., -0.09122515,\n         1.77823747, -0.87362627],\n       [-0.78012947, -1.00430931, -0.07044252, ..., -0.04368215,\n         1.75014627, -0.83369581]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
    "X_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(8,)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "model = build_sequential(lr=0.0001, input_dims=(X_train.shape[1],),output_dims=1, layerSizes=(128,64,32,16,8,4,2),activation=None,loss=\"MSE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "549/549 [==============================] - 2s 3ms/step - loss: 4.1014 - val_loss: 1.0759\n",
      "Epoch 2/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 1.0202 - val_loss: 0.7542\n",
      "Epoch 3/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.7993 - val_loss: 0.6763\n",
      "Epoch 4/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.6997 - val_loss: 0.6245\n",
      "Epoch 5/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.6311 - val_loss: 0.5857\n",
      "Epoch 6/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.5823 - val_loss: 0.5560\n",
      "Epoch 7/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.5460 - val_loss: 0.5332\n",
      "Epoch 8/500\n",
      "549/549 [==============================] - 2s 3ms/step - loss: 0.5180 - val_loss: 0.5121\n",
      "Epoch 9/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4950 - val_loss: 0.4969\n",
      "Epoch 10/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4784 - val_loss: 0.4840\n",
      "Epoch 11/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4639 - val_loss: 0.4751\n",
      "Epoch 12/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.4535 - val_loss: 0.4637\n",
      "Epoch 13/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4546\n",
      "Epoch 14/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.4469\n",
      "Epoch 15/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.4390\n",
      "Epoch 16/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4325\n",
      "Epoch 17/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4264\n",
      "Epoch 18/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4065 - val_loss: 0.4191\n",
      "Epoch 19/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.4006 - val_loss: 0.4154\n",
      "Epoch 20/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3946 - val_loss: 0.4082\n",
      "Epoch 21/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.4033\n",
      "Epoch 22/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 0.3997\n",
      "Epoch 23/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.3932\n",
      "Epoch 24/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.3878\n",
      "Epoch 25/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.3847\n",
      "Epoch 26/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.3807\n",
      "Epoch 27/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.3767\n",
      "Epoch 28/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3742\n",
      "Epoch 29/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3708\n",
      "Epoch 30/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.3701\n",
      "Epoch 31/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.3648\n",
      "Epoch 32/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3612\n",
      "Epoch 33/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3617\n",
      "Epoch 34/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3430 - val_loss: 0.3569\n",
      "Epoch 35/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.3550\n",
      "Epoch 36/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3379 - val_loss: 0.3549\n",
      "Epoch 37/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3488\n",
      "Epoch 38/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3325 - val_loss: 0.3462\n",
      "Epoch 39/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3447\n",
      "Epoch 40/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3280 - val_loss: 0.3411\n",
      "Epoch 41/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3261 - val_loss: 0.3409\n",
      "Epoch 42/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3378\n",
      "Epoch 43/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3213 - val_loss: 0.3363\n",
      "Epoch 44/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3199 - val_loss: 0.3362\n",
      "Epoch 45/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3181 - val_loss: 0.3383\n",
      "Epoch 46/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3158 - val_loss: 0.3300\n",
      "Epoch 47/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3140 - val_loss: 0.3253\n",
      "Epoch 48/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3117 - val_loss: 0.3270\n",
      "Epoch 49/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3252\n",
      "Epoch 50/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3084 - val_loss: 0.3220\n",
      "Epoch 51/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3072 - val_loss: 0.3210\n",
      "Epoch 52/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3056 - val_loss: 0.3184\n",
      "Epoch 53/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3162\n",
      "Epoch 54/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.3033 - val_loss: 0.3166\n",
      "Epoch 55/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.3147\n",
      "Epoch 56/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.3007 - val_loss: 0.3127\n",
      "Epoch 57/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3117\n",
      "Epoch 58/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2980 - val_loss: 0.3096\n",
      "Epoch 59/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2970 - val_loss: 0.3089\n",
      "Epoch 60/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2957 - val_loss: 0.3066\n",
      "Epoch 61/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2950 - val_loss: 0.3059\n",
      "Epoch 62/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2936 - val_loss: 0.3048\n",
      "Epoch 63/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2929 - val_loss: 0.3050\n",
      "Epoch 64/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2919 - val_loss: 0.3010\n",
      "Epoch 65/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2907 - val_loss: 0.3041\n",
      "Epoch 66/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2896 - val_loss: 0.2993\n",
      "Epoch 67/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.3030\n",
      "Epoch 68/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2879 - val_loss: 0.2983\n",
      "Epoch 69/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2876 - val_loss: 0.2995\n",
      "Epoch 70/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2862 - val_loss: 0.2984\n",
      "Epoch 71/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2858 - val_loss: 0.2966\n",
      "Epoch 72/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2852 - val_loss: 0.2960\n",
      "Epoch 73/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2840 - val_loss: 0.2933\n",
      "Epoch 74/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.2942\n",
      "Epoch 75/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2826 - val_loss: 0.2933\n",
      "Epoch 76/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.2932\n",
      "Epoch 77/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2813 - val_loss: 0.2913\n",
      "Epoch 78/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2805 - val_loss: 0.2904\n",
      "Epoch 79/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2798 - val_loss: 0.2919\n",
      "Epoch 80/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2803 - val_loss: 0.2906\n",
      "Epoch 81/500\n",
      "549/549 [==============================] - 1s 3ms/step - loss: 0.2792 - val_loss: 0.2896\n",
      "Epoch 82/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2779 - val_loss: 0.2901\n",
      "Epoch 83/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2778 - val_loss: 0.2902\n",
      "Epoch 84/500\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2768 - val_loss: 0.2912\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fc1768a9480>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model.fit(X_train,y_train, epochs=500, validation_data=(X_test, y_test), callbacks=[callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_cnn(output_dims, input_shape=(32,32,3), activation=\"softmax\", loss = tf.keras.losses.SparseCategoricalCrossentropy()):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(output_dims, activation=activation))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[ 59,  62,  63],\n         [ 43,  46,  45],\n         [ 50,  48,  43],\n         ...,\n         [158, 132, 108],\n         [152, 125, 102],\n         [148, 124, 103]],\n\n        [[ 16,  20,  20],\n         [  0,   0,   0],\n         [ 18,   8,   0],\n         ...,\n         [123,  88,  55],\n         [119,  83,  50],\n         [122,  87,  57]],\n\n        [[ 25,  24,  21],\n         [ 16,   7,   0],\n         [ 49,  27,   8],\n         ...,\n         [118,  84,  50],\n         [120,  84,  50],\n         [109,  73,  42]],\n\n        ...,\n\n        [[208, 170,  96],\n         [201, 153,  34],\n         [198, 161,  26],\n         ...,\n         [160, 133,  70],\n         [ 56,  31,   7],\n         [ 53,  34,  20]],\n\n        [[180, 139,  96],\n         [173, 123,  42],\n         [186, 144,  30],\n         ...,\n         [184, 148,  94],\n         [ 97,  62,  34],\n         [ 83,  53,  34]],\n\n        [[177, 144, 116],\n         [168, 129,  94],\n         [179, 142,  87],\n         ...,\n         [216, 184, 140],\n         [151, 118,  84],\n         [123,  92,  72]]],\n\n\n       [[[154, 177, 187],\n         [126, 137, 136],\n         [105, 104,  95],\n         ...,\n         [ 91,  95,  71],\n         [ 87,  90,  71],\n         [ 79,  81,  70]],\n\n        [[140, 160, 169],\n         [145, 153, 154],\n         [125, 125, 118],\n         ...,\n         [ 96,  99,  78],\n         [ 77,  80,  62],\n         [ 71,  73,  61]],\n\n        [[140, 155, 164],\n         [139, 146, 149],\n         [115, 115, 112],\n         ...,\n         [ 79,  82,  64],\n         [ 68,  70,  55],\n         [ 67,  69,  55]],\n\n        ...,\n\n        [[175, 167, 166],\n         [156, 154, 160],\n         [154, 160, 170],\n         ...,\n         [ 42,  34,  36],\n         [ 61,  53,  57],\n         [ 93,  83,  91]],\n\n        [[165, 154, 128],\n         [156, 152, 130],\n         [159, 161, 142],\n         ...,\n         [103,  93,  96],\n         [123, 114, 120],\n         [131, 121, 131]],\n\n        [[163, 148, 120],\n         [158, 148, 122],\n         [163, 156, 133],\n         ...,\n         [143, 133, 139],\n         [143, 134, 142],\n         [143, 133, 144]]],\n\n\n       [[[255, 255, 255],\n         [253, 253, 253],\n         [253, 253, 253],\n         ...,\n         [253, 253, 253],\n         [253, 253, 253],\n         [253, 253, 253]],\n\n        [[255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255],\n         ...,\n         [255, 255, 255],\n         [255, 255, 255],\n         [255, 255, 255]],\n\n        [[255, 255, 255],\n         [254, 254, 254],\n         [254, 254, 254],\n         ...,\n         [254, 254, 254],\n         [254, 254, 254],\n         [254, 254, 254]],\n\n        ...,\n\n        [[113, 120, 112],\n         [111, 118, 111],\n         [105, 112, 106],\n         ...,\n         [ 72,  81,  80],\n         [ 72,  80,  79],\n         [ 72,  80,  79]],\n\n        [[111, 118, 110],\n         [104, 111, 104],\n         [ 99, 106,  98],\n         ...,\n         [ 68,  75,  73],\n         [ 70,  76,  75],\n         [ 78,  84,  82]],\n\n        [[106, 113, 105],\n         [ 99, 106,  98],\n         [ 95, 102,  94],\n         ...,\n         [ 78,  85,  83],\n         [ 79,  85,  83],\n         [ 80,  86,  84]]],\n\n\n       ...,\n\n\n       [[[ 35, 178, 235],\n         [ 40, 176, 239],\n         [ 42, 176, 241],\n         ...,\n         [ 99, 177, 219],\n         [ 79, 147, 197],\n         [ 89, 148, 189]],\n\n        [[ 57, 182, 234],\n         [ 44, 184, 250],\n         [ 50, 183, 240],\n         ...,\n         [156, 182, 200],\n         [141, 177, 206],\n         [116, 149, 175]],\n\n        [[ 98, 197, 237],\n         [ 64, 189, 252],\n         [ 69, 192, 245],\n         ...,\n         [188, 195, 206],\n         [119, 135, 147],\n         [ 61,  79,  90]],\n\n        ...,\n\n        [[ 73,  79,  77],\n         [ 53,  63,  68],\n         [ 54,  68,  80],\n         ...,\n         [ 17,  40,  64],\n         [ 21,  36,  51],\n         [ 33,  48,  49]],\n\n        [[ 61,  68,  75],\n         [ 55,  70,  86],\n         [ 57,  79, 103],\n         ...,\n         [ 24,  48,  72],\n         [ 17,  35,  53],\n         [  7,  23,  32]],\n\n        [[ 44,  56,  73],\n         [ 46,  66,  88],\n         [ 49,  77, 105],\n         ...,\n         [ 27,  52,  77],\n         [ 21,  43,  66],\n         [ 12,  31,  50]]],\n\n\n       [[[189, 211, 240],\n         [186, 208, 236],\n         [185, 207, 235],\n         ...,\n         [175, 195, 224],\n         [172, 194, 222],\n         [169, 194, 220]],\n\n        [[194, 210, 239],\n         [191, 207, 236],\n         [190, 206, 235],\n         ...,\n         [173, 192, 220],\n         [171, 191, 218],\n         [167, 190, 216]],\n\n        [[208, 219, 244],\n         [205, 216, 240],\n         [204, 215, 239],\n         ...,\n         [175, 191, 217],\n         [172, 190, 216],\n         [169, 191, 215]],\n\n        ...,\n\n        [[207, 199, 181],\n         [203, 195, 175],\n         [203, 196, 173],\n         ...,\n         [135, 132, 127],\n         [162, 158, 150],\n         [168, 163, 151]],\n\n        [[198, 190, 170],\n         [189, 181, 159],\n         [180, 172, 147],\n         ...,\n         [178, 171, 160],\n         [175, 169, 156],\n         [175, 169, 154]],\n\n        [[198, 189, 173],\n         [189, 181, 162],\n         [178, 170, 149],\n         ...,\n         [195, 184, 169],\n         [196, 189, 171],\n         [195, 190, 171]]],\n\n\n       [[[229, 229, 239],\n         [236, 237, 247],\n         [234, 236, 247],\n         ...,\n         [217, 219, 233],\n         [221, 223, 234],\n         [222, 223, 233]],\n\n        [[222, 221, 229],\n         [239, 239, 249],\n         [233, 234, 246],\n         ...,\n         [223, 223, 236],\n         [227, 228, 238],\n         [210, 211, 220]],\n\n        [[213, 206, 211],\n         [234, 232, 239],\n         [231, 233, 244],\n         ...,\n         [220, 220, 232],\n         [220, 219, 232],\n         [202, 203, 215]],\n\n        ...,\n\n        [[150, 143, 135],\n         [140, 135, 127],\n         [132, 127, 120],\n         ...,\n         [224, 222, 218],\n         [230, 228, 225],\n         [241, 241, 238]],\n\n        [[137, 132, 126],\n         [130, 127, 120],\n         [125, 121, 115],\n         ...,\n         [181, 180, 178],\n         [202, 201, 198],\n         [212, 211, 207]],\n\n        [[122, 119, 114],\n         [118, 116, 110],\n         [120, 116, 111],\n         ...,\n         [179, 177, 173],\n         [164, 164, 162],\n         [163, 163, 161]]]], dtype=uint8)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn(10)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 1.7858 - accuracy: 0.3773 - val_loss: 1.4198 - val_accuracy: 0.4772\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 1.3482 - accuracy: 0.5181 - val_loss: 1.3441 - val_accuracy: 0.5355\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1870 - accuracy: 0.5824 - val_loss: 1.1655 - val_accuracy: 0.5967\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 1.0817 - accuracy: 0.6223 - val_loss: 1.1306 - val_accuracy: 0.6081\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.9976 - accuracy: 0.6524 - val_loss: 1.1161 - val_accuracy: 0.6223\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.9307 - accuracy: 0.6767 - val_loss: 1.0942 - val_accuracy: 0.6200\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8707 - accuracy: 0.6954 - val_loss: 1.0823 - val_accuracy: 0.6390\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.8226 - accuracy: 0.7133 - val_loss: 1.0591 - val_accuracy: 0.6459\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7796 - accuracy: 0.7292 - val_loss: 1.0932 - val_accuracy: 0.6498\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7394 - accuracy: 0.7427 - val_loss: 1.0692 - val_accuracy: 0.6581\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn(10)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    validation_data=(test_images, test_labels), callbacks=[callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5196152422706632"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.27**0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}